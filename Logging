Logging

Logging is important to show errors, info, and debug data about an Application

When you run one app it is easy to look for the log
  - just opn the "app".log file
  - or if deployed as a pod with kubectl logs.
With K8s, 1 application will be running as one or many pods.
  - Finding an error will be much more difficult
    -What pod do you have to look at?

Kubectl get logs to get the log details about a pod.

 - You would have to
  Look up the pod name
  The container names
  and then run kubectl logs for every container in every pod that is running for an app.

  Note You can use both kubectl log and kubectl logs.

Log Aggregation is the answer.
  - Not kubernetes specific, exist in syslog since the 1980s

Log Aggregation is now often implemented with more modern tools.
  - The ELK Stack (ElasticSearch Logstsh and Kibana)
  - Several Hosted service like loggly.com, papertrailapp.com
    etc.

This logging solution will be based on
  - Fluentd (for log forwarding)
  - Elasticsearch (for log indexing)
  - Kibana (for visualisation)
  - LogTrail (easy ui to show logs) a plugin for Kibana

This solution is easily customizable to create custom dashboards to show what is
important to you.


Once the cluster is up and running check on the basics and label the nodes.

Kubectl get nodes

kubectl get nodes --show-labels

Label the nodes:
----------------

Can manually label  the nodes but automation is better.

kubectl label nodes <NameOfNode>

Automated:
----------
for i in 'kubectl get node | cut -d' ' -f 1 | grep internal' ; do kubectl label nodes ${i} beta.kubernetes.io/fluentd-ds-ready=true; done

Decomposition of automated label script:
----------------------------------------

for i in 'kubectl get node   ==for index "i" in each of the stdout of kubectl get node
| cut -d' ' -f 1              == give me the first part of the stdout
| grep internal' ;            == grep on the internal part of the hostname
do kubectl label nodes ${i} beta.kubernetes.io/fluentd-ds-ready=true;
        == label each node using kubectl with the phrase   fluentd-ds-ready=true
done                          == finish script.

This didn't work for me:
ERRORS:
error: unknown shorthand flag: 'd' in -d
error: the path "1" does not exist

manually label the nodes:
kubectl label nodes <node-name> <label-key>=<label-value>

ip-172-20-36-178.ec2.internal   Ready     node      12h       v1.8.6
ip-172-20-40-253.ec2.internal   Ready     node      12h       v1.8.6
ip-172-20-42-22.ec2.internal    Ready     master    12h       v1.8.6
ip-172-20-51-73.ec2.internal    Ready     node      12h       v1.8.6

kubectl label nodes   ip-172-20-36-178.ec2.internal  fluentd-ds-ready=true
kubectl label nodes   ip-172-20-40-253.ec2.internal fluentd-ds-ready=true
kubectl label nodes   ip-172-20-42-22.ec2.internal  fluentd-ds-ready=true
kubectl label nodes   ip-172-20-51-73.ec2.internal  fluentd-ds-ready=true

Done.






....
